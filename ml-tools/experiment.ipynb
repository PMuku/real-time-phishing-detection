{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1535d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from url_features import featurize_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/labelled_urls.csv\")\n",
    "df.head()\n",
    "\n",
    "df = df.drop(columns=[\"label\"])\n",
    "df.rename(columns={\"result\": \"label\"}, inplace=True)\n",
    "\n",
    "df_benign = df[df[\"label\"] == 0]\n",
    "df_phishing = df[df[\"label\"] == 1]\n",
    "ratio = 1/20\n",
    "n_phish = len(df_phishing)\n",
    "df_ben_sampled = df_benign.sample(n=int(n_phish * ratio), random_state=42)\n",
    "df_final = pd.concat([df_ben_sampled, df_phishing]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = df_final[\"url\"].tolist()\n",
    "labels = df_final[\"label\"].tolist()\n",
    "\n",
    "features = pd.DataFrame(featurize_urls(urls))\n",
    "features[\"label\"] = labels\n",
    "\n",
    "X, y = features.drop(columns=[\"label\", \"path_length\"]), features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "inspection = pd.DataFrame({\n",
    "    \"url\": X_test.index.map(lambda i: urls[i]),\n",
    "    \"phishing_probability\": y_pred_probs,\n",
    "    \"label\": y_test.values\n",
    "})\n",
    "inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b62c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.named_steps[\"clf\"]\n",
    "\n",
    "importance = pd.Series(\n",
    "    clf.coef_[0],\n",
    "    index=X.columns\n",
    ").sort_values(key=abs, ascending=False)\n",
    "\n",
    "importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736032d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackoverflow_url = \"https://stackoverflow.com/questions/12345/how-to-use-train-test-split\"\n",
    "\n",
    "so_features = pd.DataFrame(\n",
    "    featurize_urls([stackoverflow_url])\n",
    ")\n",
    "so_features = so_features[X.columns]\n",
    "so_prob = pipeline.predict_proba(so_features)[0, 1]\n",
    "so_prob # ~0.16 -> too high for a known benign URL\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
